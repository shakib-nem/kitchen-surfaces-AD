{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from typing import Optional, Iterable\n",
    "import captum.attr  # Ensure you have Captum installed: pip install captum\n",
    "\n",
    "# --- Integrated GradCam Class ---\n",
    "class GradCam(torch.nn.Module):\n",
    "    def __init__(self, model: torch.nn.Module, name_layer: str, mean: list, std: list) -> None:\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Extract the desired layer from the model.\n",
    "        names_mid = name_layer.split(\".\")\n",
    "        layer = model\n",
    "        for name in names_mid:\n",
    "            layer = getattr(layer, name)\n",
    "        self.layer = layer\n",
    "        \n",
    "        # Captum's LayerGradCam\n",
    "        self.cam = captum.attr.LayerGradCam(self._forward_only_logits, self.layer)\n",
    "        \n",
    "        # Mean/std for potential unnormalization\n",
    "        self.mean = mean\n",
    "        self.std  = std\n",
    "\n",
    "    def _forward_only_logits(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Return only the logits from the model's output.\"\"\"\n",
    "        logits, _ = self.model(x)\n",
    "        return logits\n",
    "\n",
    "    def auto_select_indices(self, logits: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Select the top predicted class index for each sample.\"\"\"\n",
    "        return torch.argmax(logits, dim=1)\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        indices: Optional[Iterable[int]] = None,\n",
    "        with_upsample: bool = False\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Returns raw Grad-CAM feature maps (float) of shape [B, 1, H, W] if with_upsample=True.\n",
    "        \"\"\"\n",
    "        if indices is None:\n",
    "            logits = self._forward_only_logits(x)\n",
    "            indices = self.auto_select_indices(logits)\n",
    "\n",
    "        x = x.requires_grad_(True)\n",
    "        featuremaps = self.cam.attribute(x, target=indices, relu_attributions=True)\n",
    "        \n",
    "        if with_upsample:\n",
    "            featuremaps = F.interpolate(\n",
    "                featuremaps,\n",
    "                size=x.shape[-2:],\n",
    "                mode='bilinear',\n",
    "                align_corners=True\n",
    "            )\n",
    "        return featuremaps  # shape [B, 1, H, W]\n",
    "    \n",
    "    @staticmethod\n",
    "    def featuremaps_to_heatmaps(x: torch.Tensor) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Applies per-sample minâ€“max normalization and then uses cv2.applyColorMap(...)\n",
    "        to generate a heatmap for each feature map.\n",
    "        \n",
    "        x: [B, 1, H, W]\n",
    "        returns: [B, H, W, 3] in BGR format.\n",
    "        \"\"\"\n",
    "        B, _, H, W = x.shape\n",
    "        featuremaps = x.squeeze(1).detach().cpu().numpy()\n",
    "        heatmaps = np.zeros((B, H, W, 3), dtype=np.uint8)\n",
    "\n",
    "        for i_map, fmap in enumerate(featuremaps):\n",
    "            # Normalize each sample to 0-255.\n",
    "            hmap = cv2.normalize(fmap, None, 0, 255, cv2.NORM_MINMAX)\n",
    "            hmap = cv2.applyColorMap(hmap.astype(np.uint8), cv2.COLORMAP_HOT)\n",
    "            heatmaps[i_map] = hmap\n",
    "\n",
    "        return heatmaps\n",
    "\n",
    "# --- Data Loading Class ---\n",
    "class BurgerData(Dataset):\n",
    "    def __init__(self, imgSize: int, stride: int, image_folder: str, transform=None) -> None:\n",
    "        super().__init__()\n",
    "        self.imgSize = imgSize\n",
    "        self.stride = stride\n",
    "        self.image_folder = image_folder\n",
    "        self.transform = transform\n",
    "\n",
    "        # Use the first image found in the folder.\n",
    "        self.image_path = None\n",
    "        for f in os.listdir(image_folder):\n",
    "            if f.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                self.image_path = os.path.join(image_folder, f)\n",
    "                break\n",
    "\n",
    "        if self.image_path is None:\n",
    "            raise FileNotFoundError(f\"No image found in {image_folder}\")\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return 1\n",
    "\n",
    "    def __getitem__(self, index) -> torch.Tensor:\n",
    "        if index != 0:\n",
    "            raise IndexError(\"Index out of range for single-image dataset\")\n",
    "        img = Image.open(self.image_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img_tensor = self.transform(img)\n",
    "        else:\n",
    "            raise ValueError(\"Transform is not provided.\")\n",
    "        return img_tensor\n",
    "\n",
    "# --- Main Code ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Define normalization parameters.\n",
    "    mean = [0.6047, 0.6183, 0.5254]\n",
    "    std = [0.2732, 0.2820, 0.2739]\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=mean, std=std)\n",
    "    ])\n",
    "\n",
    "    # Create the dataset (assumes one image in the folder).\n",
    "    data = BurgerData(\n",
    "        imgSize=256,\n",
    "        stride=256,\n",
    "        image_folder=\"/home/shn/data/Anomalies/black hole\",  # Adjust path as needed.\n",
    "        transform=transform\n",
    "    )\n",
    "\n",
    "    # Load image and move to GPU.\n",
    "    img_tensor = data[0].unsqueeze(0).to(\"cuda\")\n",
    "\n",
    "    # --- Model Loading ---\n",
    "    # Here we assume you have a model class `CutPaste` that can be loaded from a checkpoint.\n",
    "    from train2 import CutPaste  # You can still import your model.\n",
    "    checkpoint_path = \"/home/shn/tb_logs/cutAndPaste/version_38/checkpoints/weights.ckpt\"\n",
    "    model = CutPaste.load_from_checkpoint(checkpoint_path=checkpoint_path).eval().to(\"cuda\")\n",
    "\n",
    "    # --- Grad-CAM Initialization ---\n",
    "    grad_cam = GradCam(\n",
    "        model.model,  # Assumes the actual model is inside model.model.\n",
    "        \"encoder.conv1\",  # Ensure this layer exists in your model.\n",
    "        mean=[0.5815, 0.5940, 0.5015],\n",
    "        std=[0.2716, 0.2812, 0.2710]\n",
    "    )\n",
    "\n",
    "    # Compute Grad-CAM. Output shape: [B, 1, H, W].\n",
    "    raw_featuremap = grad_cam.forward(img_tensor, indices=1, with_upsample=True)\n",
    "\n",
    "    # --- Custom Heatmap Creation with Scaling ---\n",
    "    # Extract raw activation values as a 2D array.\n",
    "    raw_np = raw_featuremap.squeeze().detach().cpu().numpy()  # shape: [H, W]\n",
    "    \n",
    "    # Multiply the raw activation values by 10,000.\n",
    "    scale_factor = 10000\n",
    "    raw_np_scaled = raw_np * scale_factor\n",
    "\n",
    "    # Compute the actual min and max of the scaled activations.\n",
    "    fmin = raw_np_scaled.min()\n",
    "    fmax = raw_np_scaled.max()\n",
    "\n",
    "    # Normalize the scaled activations to [0, 1] using the actual range.\n",
    "    raw_norm = (raw_np_scaled - fmin) / (fmax - fmin + 1e-8)\n",
    "    # Scale to [0, 255] and convert to uint8.\n",
    "    raw_uint8 = (raw_norm * 255).astype(np.uint8)\n",
    "\n",
    "    # Apply colormap using OpenCV.\n",
    "    heatmap_bgr = cv2.applyColorMap(raw_uint8, cv2.COLORMAP_HOT)\n",
    "    heatmap_rgb = cv2.cvtColor(heatmap_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Create a ScalarMappable for a colorbar that reflects [fmin, fmax].\n",
    "    norm = mcolors.Normalize(vmin=fmin, vmax=fmax)\n",
    "    cmap = cm.get_cmap('hot')\n",
    "    sm = cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "    sm.set_array([])\n",
    "\n",
    "    # --- Visualization ---\n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    ax.imshow(heatmap_rgb)\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(\"Anomaly Map (Grad-CAM)\", fontsize=14)\n",
    "\n",
    "    # Attach a colorbar showing the actual range of scaled raw activation values.\n",
    "    cbar = fig.colorbar(sm, ax=ax, fraction=0.046, pad=0.04)\n",
    "    cbar.set_label(\"Raw Activation Value (x10,000)\", rotation=270, labelpad=15)\n",
    "    cbar.ax.tick_params(labelsize=10)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
